# ADR-02: Выбор Faster-Whisper для распознавания речи в HomeGuru

**Дата:** 2025-10-12  
**Статус:** Принято (Accepted)  
**Авторы:** Команда разработки  

---

## Контекст

При разработке функционала обработки голосовых сообщений для HomeGuru - ИИ-дизайнера интерьеров в Telegram необходимо выбрать решение для транскрибации аудио в текст (Speech-to-Text).

### Требования к решению

**Функциональные:**
- Высокое качество распознавания русской и английской речи
- Поддержка аудио форматов Telegram (OGG/Opus)
- Достаточная скорость обработки для комфортного UX
- Надежная работа с различными акцентами и качеством записи

**Нефункциональные:**
- Минимальные эксплуатационные расходы для MVP
- Простота интеграции и развертывания
- Следование принципу KISS (Keep It Simple, Stupid)
- Возможность локального развертывания без зависимости от внешних API
- Предсказуемые затраты (без стоимости за каждый запрос)

### Рассмотренные варианты

#### 1. OpenAI Whisper API
**Плюсы:**
- Простая интеграция через API
- Высокое качество распознавания
- Нет необходимости в локальных ресурсах

**Минусы:**
- Дополнительные затраты на каждый запрос ($0.006/минуту)
- Зависимость от внешнего сервиса
- Задержки при отправке аудио через сеть
- Проблемы приватности (аудио уходит на внешний сервер)

#### 2. Google Cloud Speech-to-Text
**Плюсы:**
- Высокое качество распознавания
- Поддержка множества языков

**Минусы:**
- Сложная настройка и авторизация
- Дополнительные затраты
- Оверинжиниринг для MVP

#### 3. Оригинальный Whisper (openai/whisper)
**Плюсы:**
- Открытый исходный код
- Локальное развертывание
- Бесплатное использование

**Минусы:**
- Медленная скорость инференса (PyTorch)
- Высокие требования к ресурсам
- Неоптимизированная производительность

#### 4. Faster-Whisper (guillaumekln/faster-whisper)
**Плюсы:**
- В 4-5 раз быстрее оригинального Whisper
- Локальное развертывание
- Бесплатное использование (без API costs)
- Низкие требования к ресурсам
- Простая интеграция (Python библиотека)
- Оптимизирован через CTranslate2
- Поддержка разных размеров моделей (tiny, base, small, medium, large)

**Минусы:**
- Требует локальных вычислительных ресурсов
- Необходимо управление версиями моделей

## Решение

Выбрана библиотека **Faster-Whisper с моделью base** для локального распознавания речи в HomeGuru.

### Ключевые параметры решения

#### Используемая модель: `base`
- **Размер:** ~140 MB
- **Память:** ~1 GB RAM
- **Скорость:** ~2-3x realtime на CPU
- **Качество:** Отличный баланс точности и скорости для русского и английского языков

#### Конфигурация
```python
from faster_whisper import WhisperModel

model = WhisperModel(
    model_size="base",
    device="cpu",           # CPU достаточно для base модели
    compute_type="int8"     # Квантизация для ускорения
)
```

#### Параметры в .env
```env
# Speech Recognition (Faster-Whisper)
WHISPER_MODEL=base
WHISPER_DEVICE=cpu
```

### Архитектура интеграции

```
Telegram Voice Message
         ↓
   TelegramBot
         ↓
   MediaProcessor
         ↓
   Download OGG/Opus
         ↓
   Faster-Whisper (base)
   - Local inference
   - CPU/GPU support
   - ~2-3s для 10-sec аудио
         ↓
   Transcribed Text
         ↓
   MessageHandler
   (как обычное текстовое сообщение)
```

### Преимущества выбора Faster-Whisper base

#### 1. Оптимальный баланс скорости и качества
- **Base модель** обеспечивает достаточную точность для большинства голосовых запросов
- Скорость обработки 2-3x realtime на CPU (голосовое 10 сек → транскрибация 3-4 сек)
- Для типичных коротких голосовых сообщений (5-30 сек) время обработки приемлемое

#### 2. Нулевые эксплуатационные расходы
- Нет затрат на API вызовы
- Предсказуемая стоимость инфраструктуры
- Важно для MVP на этапе валидации продукта

#### 3. Простота и KISS
- Одна зависимость: `pip install faster-whisper`
- Минимальная конфигурация (2 параметра)
- Не требует сложной настройки API ключей
- Соответствует принципу минимализма проекта

#### 4. Локальное развертывание
- Отсутствие зависимости от внешних сервисов
- Работает оффлайн
- Приватность: аудио не покидает сервер
- Устойчивость к сбоям внешних API

#### 5. Масштабируемость
- При росте нагрузки легко добавить GPU ускорение (изменить `device="cuda"`)
- Возможность перейти на модель `small` или `medium` для повышения качества
- Горизонтальное масштабирование через несколько инстансов

#### 6. Следование принципам проекта
- **KISS**: Простое локальное решение без внешних API
- **MVP-подход**: Минимальные затраты и быстрый старт
- **Никакого оверинжиниринга**: Не решаем проблемы, которых еще нет

### Технические детали

#### Зависимости
```toml
[project.dependencies]
# ... existing dependencies
faster-whisper = "^1.0.0"
```

#### Реализация в MediaProcessor
```python
from faster_whisper import WhisperModel
from pathlib import Path

class MediaProcessor:
    def __init__(self, config: Config):
        self.whisper_model = WhisperModel(
            model_size=config.whisper_model,  # "base"
            device=config.whisper_device,     # "cpu"
            compute_type="int8"
        )
    
    async def transcribe_audio(self, audio_path: Path) -> str:
        """Транскрибация аудио файла в текст"""
        segments, info = self.whisper_model.transcribe(
            str(audio_path),
            language="ru",  # Можно добавить auto-detection
            beam_size=5
        )
        
        # Объединяем все сегменты
        text = " ".join(segment.text for segment in segments)
        return text.strip()
```

#### Обработка в MessageHandler
```python
async def process_voice_message(self, user_id: int, voice_file_id: str) -> str:
    """Обработка голосового сообщения"""
    # 1. Скачать аудио
    audio_path = await self.media_processor.download_voice(voice_file_id)
    
    # 2. Транскрибировать через Faster-Whisper
    transcribed_text = await self.media_processor.transcribe_audio(audio_path)
    
    # 3. Обработать как обычное текстовое сообщение
    response = await self.process_text_message(user_id, transcribed_text)
    
    return response
```

### Производительность

#### Целевые метрики
- **Голосовое 5 сек:** транскрибация ~1-2 сек
- **Голосовое 10 сек:** транскрибация ~3-4 сек
- **Голосовое 30 сек:** транскрибация ~10-12 сек

#### Требования к ресурсам (base модель)
- **RAM:** ~1 GB для модели
- **CPU:** Любой современный CPU (2+ cores)
- **Хранилище:** ~140 MB для модели
- **GPU:** Опционально (можно ускорить до 10x)

## Последствия

### Положительные

#### Экономия затрат
- Нулевые затраты на API транскрибации
- Важно для MVP на этапе валидации
- Предсказуемая стоимость инфраструктуры

#### Простота интеграции
- Одна Python библиотека
- Минимальная конфигурация (2 параметра в .env)
- Следование принципу KISS

#### Приватность
- Голосовые сообщения не покидают сервер
- Отсутствие зависимости от сторонних сервисов

#### Производительность
- Достаточная скорость для комфортного UX
- Возможность ускорения через GPU при необходимости

#### Надежность
- Локальное развертывание исключает сбои внешних API
- Детерминированное поведение

### Отрицательные

#### Дополнительные требования к серверу
- Требуется ~1 GB RAM для модели base
- Требуется CPU для инференса
- **Митигация:** Современные VPS легко справляются с этими требованиями

#### Необходимость управления моделью
- Модель нужно скачать при первом запуске
- Версионирование модели
- **Митигация:** Faster-Whisper автоматически скачивает модель при первом использовании

#### Время обработки на CPU
- Slower чем специализированные GPU-серверы крупных провайдеров
- Для длинных аудио (>1 мин) время обработки может быть заметным
- **Митигация:** Типичные голосовые в Telegram короткие (5-30 сек); при росте можно добавить GPU

#### Качество может быть ниже Enterprise решений
- Base модель может иметь ошибки с сильными акцентами или шумом
- **Митигация:** Можно легко перейти на модель `small` или `medium` при необходимости

### Риски и их митигация

#### Риск: Недостаточная точность распознавания
**Митигация:** 
- Мониторинг качества транскрибации через LangSmith
- Возможность апгрейда до модели `small` (+100 MB, +50% точность)
- Добавление языковой модели для post-processing (опционально)

#### Риск: Медленная обработка длинных аудио
**Митигация:**
- Ограничение длины голосовых сообщений (например, 60 сек)
- Возможность добавления GPU (изменение 1 параметра: `device="cuda"`)
- Уведомление пользователя о процессе обработки

#### Риск: Проблемы с форматами аудио
**Митигация:**
- Telegram всегда отправляет OGG/Opus
- Faster-Whisper поддерживает все основные форматы
- Добавление конвертации через FFmpeg при необходимости

## Альтернативы для будущего

### Если потребуется улучшение качества:
1. **Faster-Whisper small/medium** - улучшенная точность (+50-100%)
2. **GPU ускорение** - 10x ускорение инференса
3. **OpenAI Whisper API** - максимальное качество, но с затратами

### Если потребуется масштабирование:
1. **Separate transcription service** - выделенный микросервис
2. **Async queue processing** - очередь для обработки аудио
3. **Caching** - кэширование результатов для повторяющихся аудио

## Критерии успеха

Данное решение считается успешным, если:

1. ✅ Голосовые сообщения успешно транскрибируются в текст
2. ✅ Точность распознавания >90% для чистой речи
3. ✅ Время обработки голосового 10 сек <5 сек на CPU
4. ✅ Нулевые затраты на API транскрибации
5. ✅ Простая интеграция (< 100 строк кода)
6. ✅ Стабильная работа без зависимости от внешних сервисов
7. ✅ Положительная обратная связь от пользователей о качестве распознавания
8. ✅ Возможность легкого апгрейда при необходимости

## Связанные решения

- [ADR-01: Архитектура HomeGuru MVP](ADR-01.md) - общая архитектура системы
- [vision.md](../vision.md) - техническое видение проекта

## Ссылки

- [Faster-Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [OpenAI Whisper](https://github.com/openai/whisper)
- [CTranslate2](https://github.com/OpenNMT/CTranslate2)

---

**Последнее обновление:** 2025-10-12

